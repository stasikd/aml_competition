{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.dialog-21.ru/media/5806/gusevi112.pdf\n",
    "\n",
    "https://arxiv.org/pdf/2105.08206.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T22:21:39.196141Z",
     "start_time": "2023-05-22T22:21:39.187436Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/demid-vm/home/demid-vm/test_dir'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyENczXbyhzy"
   },
   "source": [
    "### Tagger inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:15:52.947373Z",
     "start_time": "2023-05-14T17:15:16.779643Z"
    },
    "id": "Bfan4A5Mxo1Z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "tagger_model_name = \"IlyaGusev/rubertconv_toxic_editor\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_num = 0 if device == \"cuda\" else -1\n",
    "tagger_tokenizer = AutoTokenizer.from_pretrained(tagger_model_name)\n",
    "tagger_pipe = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=tagger_model_name,\n",
    "    tokenizer=tagger_model_name,\n",
    "    framework=\"pt\",\n",
    "    device=device_num,\n",
    "    aggregation_strategy=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:16:16.453388Z",
     "start_time": "2023-05-14T17:15:58.176321Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_vc1rKnzIwN",
    "outputId": "448975a5-a5c7-486f-d838-9252c614dbc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'delete', 'score': 0.57686865, 'word': 'Ёпта,', 'start': 0, 'end': 5}, {'entity_group': 'equal', 'score': 0.9623802, 'word': 'меня зовут', 'start': 6, 'end': 16}, {'entity_group': 'replace', 'score': 0.69702196, 'word': 'придурок', 'start': 17, 'end': 25}, {'entity_group': 'equal', 'score': 0.86356926, 'word': 'и я живу', 'start': 26, 'end': 34}, {'entity_group': 'replace', 'score': 0.8265923, 'word': 'в жопе', 'start': 35, 'end': 41}]\n"
     ]
    }
   ],
   "source": [
    "text = \"Ёпта, меня зовут придурок и я живу в жопе\"\n",
    "tagger_predictions = tagger_pipe([text], batch_size=1)\n",
    "sample_predictions = tagger_predictions[0]\n",
    "print(sample_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmLcnCANzZtB"
   },
   "source": [
    "### Template building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:17:09.886824Z",
     "start_time": "2023-05-14T17:17:09.882847Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3REkP6v_yFka",
    "outputId": "442fe2b3-5e48-4f09-a3e4-7efef36aa8c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "меня зовут [MASK] и я живу [MASK]\n"
     ]
    }
   ],
   "source": [
    "template = []\n",
    "for group in sample_predictions:\n",
    "    tag = group[\"entity_group\"]\n",
    "    phrase = group[\"word\"]\n",
    "    pad_index = phrase.find(tagger_tokenizer.pad_token)\n",
    "    if pad_index != -1:\n",
    "        phrase = phrase[:pad_index]\n",
    "    if tag == \"delete\":\n",
    "        continue\n",
    "    if tag == \"replace\":\n",
    "        phrase = tagger_tokenizer.mask_token\n",
    "    template.append(phrase.strip())\n",
    "template = \" \".join(template)\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:17:13.473817Z",
     "start_time": "2023-05-14T17:17:13.461300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7GiADZ1MzhaQ",
    "outputId": "11e18a72-ca73-4352-fb74-d957295f1ac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "меня зовут <extra_id_0> и я живу <extra_id_1>\n"
     ]
    }
   ],
   "source": [
    "MASK_TEMPLATE = \" <extra_id_{}> \"\n",
    "\n",
    "def convert_template_to_t5(template, orig_mask_token):\n",
    "    current_pos = 0\n",
    "    mask_pos = template.find(orig_mask_token, current_pos)\n",
    "    mask_num = 0\n",
    "    while mask_pos != -1:\n",
    "        end_mask_pos = mask_pos + len(orig_mask_token)\n",
    "        template = template[:mask_pos] + MASK_TEMPLATE.format(mask_num) + template[end_mask_pos:]\n",
    "        template = \" \".join(template.split())\n",
    "        current_pos = end_mask_pos\n",
    "        mask_pos = template.find(orig_mask_token, current_pos)\n",
    "        mask_num += 1\n",
    "    return template\n",
    "\n",
    "template = convert_template_to_t5(template, tagger_tokenizer.mask_token)\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-bhKh-2zsit"
   },
   "source": [
    "### Template filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:17:47.214453Z",
     "start_time": "2023-05-14T17:17:16.752875Z"
    },
    "id": "zxVgtD3_zucL"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gen_model_name = \"IlyaGusev/sber_rut5_filler\"\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(gen_model_name)\n",
    "gen_model = AutoModelForSeq2SeqLM.from_pretrained(gen_model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:17:57.305881Z",
     "start_time": "2023-05-14T17:17:56.383277Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-vq0rEqzXlS",
    "outputId": "af991a9b-eee9-4efb-ba95-3c86f03bb356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_id_0> нехороший человек <extra_id_1> в беде <extra_id_2>\n",
      "меня зовут нехороший человек и я живу в беде\n"
     ]
    }
   ],
   "source": [
    "input_ids = gen_tokenizer(\n",
    "    text,\n",
    "    text_pair=template,\n",
    "    add_special_tokens=True,\n",
    "    max_length=200,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ").input_ids.to(gen_model.device)\n",
    "\n",
    "output_ids = gen_model.generate(\n",
    "    input_ids=input_ids,\n",
    "    num_beams=5,\n",
    "    num_return_sequences=1,\n",
    "    max_length=300,\n",
    "    repetition_penalty=2.5\n",
    ")\n",
    "output_ids = output_ids[0]\n",
    "fillers = gen_tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "print(fillers)\n",
    "\n",
    "mask_count = template.count(\"extra_id\")\n",
    "target = template\n",
    "for mask_num in range(mask_count):\n",
    "    current_mask = MASK_TEMPLATE.format(mask_num).strip()\n",
    "    next_mask = MASK_TEMPLATE.format(mask_num + 1).strip()\n",
    "    start_index = fillers.find(current_mask) + len(current_mask)\n",
    "    end_index = fillers.find(next_mask)\n",
    "    filler = fillers[start_index:end_index]\n",
    "    target = target.replace(current_mask, filler)\n",
    "target = \" \".join(target.split())\n",
    "target = target.replace(\" ,\", \",\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:21:39.985647Z",
     "start_time": "2023-05-14T17:21:39.970018Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'меня зовут нехороший человек и я живу в беде'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:31:31.807886Z",
     "start_time": "2023-05-14T17:31:31.807886Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:52:37.349603Z",
     "start_time": "2023-05-14T17:52:37.333549Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:23:19.467027Z",
     "start_time": "2023-05-14T17:23:19.357480Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.tsv.txt', sep='\\t')\n",
    "toxic_inputs = df['toxic_comment'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Inference for toxic inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T18:45:49.698961Z",
     "start_time": "2023-05-14T17:52:43.187540Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                  | 9/875 [00:33<52:46,  3.66s/it]/home/demid-vm/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 875/875 [55:05<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "detox_list = []\n",
    "\n",
    "for text in tqdm(toxic_inputs):\n",
    "\n",
    "    tagger_predictions = tagger_pipe([text], batch_size=1)\n",
    "    sample_predictions = tagger_predictions[0]\n",
    "\n",
    "    template = []\n",
    "    for group in sample_predictions:\n",
    "        tag = group[\"entity_group\"]\n",
    "        phrase = group[\"word\"]\n",
    "        pad_index = phrase.find(tagger_tokenizer.pad_token)\n",
    "        if pad_index != -1:\n",
    "            phrase = phrase[:pad_index]\n",
    "        if tag == \"delete\":\n",
    "            continue\n",
    "        if tag == \"replace\":\n",
    "            phrase = tagger_tokenizer.mask_token\n",
    "        template.append(phrase.strip())\n",
    "    template = \" \".join(template)\n",
    "\n",
    "    MASK_TEMPLATE = \" <extra_id_{}> \"\n",
    "\n",
    "    template = convert_template_to_t5(template, tagger_tokenizer.mask_token)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    gen_model_name = \"IlyaGusev/sber_rut5_filler\"\n",
    "    gen_tokenizer = AutoTokenizer.from_pretrained(gen_model_name)\n",
    "    gen_model = AutoModelForSeq2SeqLM.from_pretrained(gen_model_name).to(device)\n",
    "\n",
    "    input_ids = gen_tokenizer(\n",
    "        text,\n",
    "        text_pair=template,\n",
    "        add_special_tokens=True,\n",
    "        max_length=200,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).input_ids.to(gen_model.device)\n",
    "\n",
    "    output_ids = gen_model.generate(\n",
    "        input_ids=input_ids,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "        max_length=300,\n",
    "        repetition_penalty=2.5\n",
    "    )\n",
    "    output_ids = output_ids[0]\n",
    "    fillers = gen_tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "    mask_count = template.count(\"extra_id\")\n",
    "    target = template\n",
    "    for mask_num in range(mask_count):\n",
    "        current_mask = MASK_TEMPLATE.format(mask_num).strip()\n",
    "        next_mask = MASK_TEMPLATE.format(mask_num + 1).strip()\n",
    "        start_index = fillers.find(current_mask) + len(current_mask)\n",
    "        end_index = fillers.find(next_mask)\n",
    "        filler = fillers[start_index:end_index]\n",
    "        target = target.replace(current_mask, filler)\n",
    "    target = \" \".join(target.split())\n",
    "    target = target.replace(\" ,\", \",\")\n",
    "    detox_list.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open('output/rubertconf_toxic_1.txt', 'w') as file:\n",
    "    file.writelines([sentence+'\\n' for sentence in detox_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
